\subsection{\textsc{QSERV-PRF-10-00}: Concurrent Query Performance}
\label{qserv-prf-10-00}

\subsubsection{Requirements \label{sect:reqs}}

DMS-REQ-0356,DMS-REQ-0357.

\subsubsection{Test items}

This test will check that \product{} is able to meet average query completion time targets per query class
under a representative load of simultaneous high and low volume queries while running against an appropriately
scaled test catalog.

\subsubsection{Intercase dependencies}

\hyperref[qserv-prf-20-00]{\textsc{QSERV-PRF-20-00}},
\hyperref[qserv-prf-20-05]{\textsc{QSERV-PRF-20-05}},
\hyperref[qserv-prf-20-10]{\textsc{QSERV-PRF-20-10}},
\hyperref[qserv-prf-20-15]{\textsc{QSERV-PRF-20-15}}.

\subsubsection{Input specification}

\begin{itemize}

  \item{A test catalog of appropriate size (see schedule detail in \hyperref[qserv-prf-10]{\textsc{
  QSERV-PRF-10}}), prepared and ingested into the \product{} instance under test as detailed in
  section~\secref{sec:prep}.}

  \item{The concurrency load execution script, runQueries.py, maintained in the LSST \product{}
  github repository here: \url{https://github.com/lsst/qserv/blob/master/admin/tools/docker/deployment/in2p3/runQueries.py}}

\end{itemize}

\subsubsection{Output specification}

\begin{itemize}
  \item{Log files as generated by the runQueries.py test script.}
\end{itemize}

\subsubsection{Procedure}

\begin{enumerate}

  \item{Inspect and possibly modify the \texttt{CONCURRENCY} and \texttt{TARGET\_RATES} dictionaries in
  the runQueries.py script to adjust the concurrency mix and target execution times per query class.  Query
  mixes and target times are to be adjusted per the following schedule:

    \begin{tabular}{|l|c|c|c|c|c|c|c|}\hline
      \multicolumn{2}{|c|}{\textbf{Query Class}}
        &\textbf{2015}&\textbf{2016}&\textbf{2017}&\textbf{2018}&\textbf{2019}&\textbf{2020}\\\hline
      \multirow{2}{*}{\textbf{LV}}
        &\textbf{\# queries}  & 50 & 60 & 70 & 80 & 90 & 100 \\%\cline{2-8}
        &\textbf{time (sec)}  & 10 & 10 & 10 & 10 & 10 &  10 \\\hline
      \multirow{2}{*}{\textbf{FTSObj}}
        &\textbf{\# queries}  &  3 &  4 &  8 & 12 & 16 &  20 \\%\cline{2-8}
        &\textbf{time (hours)}& 12 &  1 &  1 &  1 &  1 &   1 \\\hline
      \multirow{2}{*}{\textbf{FTSSrc}}
        &\textbf{\# queries}  &  1 &  1 &  2 &  3 &  4 &   5 \\%\cline{2-8}
        &\textbf{time (hours)}& 12 & 12 & 12 & 12 & 12 &  12 \\\hline
      \multirow{2}{*}{\textbf{FTSFSrc}}
        &\textbf{\# queries}  &    &  1 &  2 &  3 &  4 &   5 \\%\cline{2-8}
        &\textbf{time (hours)}&    & 12 & 12 & 12 & 12 &  12 \\\hline
      \multirow{2}{*}{\textbf{joinObjSrc}}
        &\textbf{\# queries}  &  1 &  2 &  4 &  6 &  8 &  10 \\%\cline{2-8}
        &\textbf{time (hours)}& 12 & 12 & 12 & 12 & 12 &  12 \\\hline
      \multirow{2}{*}{\textbf{joinObjFSrc}}
        &\textbf{\# queries}  &    &  1 &  2 &  3 &  4 &   5 \\%\cline{2-8}
        &\textbf{time (hours)}&    & 12 & 12 & 12 & 12 &  12 \\\hline
      \multirow{2}{*}{\textbf{nearN}}
        &\textbf{\# queries}  &    &  1 &  2 &  3 &  4 &   5 \\%\cline{2-8}
        &\textbf{time (hours)}&    &  1 &  1 &  1 &  1 &   1 \\\hline
    \end{tabular}

  }

  \item{Ensure that \product{} instance under test is up to date and that there is no other concurrent
  user activity.}

  \item{Execute the runQueries.py script and let it run for at least 24hrs.}

  \item{Examine log file output and compile performance statistics for the test report.}

\end{enumerate}
